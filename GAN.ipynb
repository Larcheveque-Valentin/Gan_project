{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On importe la library comme à constantinople"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(x_train, batch_size):\n",
    "  while True:\n",
    "    # Sélectionner aléatoirement des indices pour les données d'entraînement\n",
    "    indices = np.random.randint(low=0, high=x_train.shape[0], size=batch_size)\n",
    "    # Récupérer les données d'entraînement correspondantes aux indices sélectionnés\n",
    "    x_batch = x_train[indices]\n",
    "    # Yielder les données d'entraînement sélectionnées\n",
    "    yield x_batch\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définition des deux MLP Le premier est le générateur \n",
    "Il doit générer des images de taille (28 ,28,1), à partir d'un bruit de taille noise_dim\n",
    "Le second est le discriminateur, il sort un nombre entre 0 et 1, 1 s'il est sur que l'image est vraie, 0 sinon.\n",
    "On entraine 'epochs' fois le gan et à chaque étape on entraine d'abord \n",
    "k fois le discriminateur et on entraine 1 fois le générateur à maximiser la valeur du discriminateur appliqué à une de ses images, elle sera alors plus \"vrai\" aux yeux du discriminateur, qui va de nouveau etre entrainé k fois et ainsi de suite. \n",
    "Cela permet d'avoir un générateur entrainé et un discriminateur entrainé si les bons paramètres sont utilisés.\n",
    "\n",
    "\n",
    "Les deux réseaux doivent avoir le meme nombre de couches pour ne pas entrainer de déséquilibre empêchant l'atteinte d'un équilire heuristique entre le générateur et le discriminateur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dim=100\n",
    "display_server=\"http://localhost\"\n",
    "display_port=6087\n",
    "batch_size=64\n",
    "num_img_channel=1\n",
    "img_size=28\n",
    "sample_interval=64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Importation des données\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "# Charger les données MNIST\n",
    "\n",
    "# Obtenir les indices des images de 2 dans l'ensemble d'entraînement\n",
    "two_indices = np.where(y_train == 1)[0]\n",
    "two_indices_test= np.where(y_test == 1)[0]\n",
    "# Sélectionner les images de 2 dans l'ensemble d'entraînement\n",
    "x_train_two = x_train[two_indices]\n",
    "\n",
    "y_train_two = y_train[two_indices]\n",
    "\n",
    "x_test_two = x_test[two_indices_test]\n",
    "\n",
    "y_test_two = y_test[two_indices_test]\n",
    "\n",
    "# Normaliser les données d'entraînement et de test\n",
    "\n",
    "\n",
    "# Redimensionner les données d'entraînement et de test en forme (batch_size, 28, 28, 1)\n",
    "\n",
    "x_train = x_train.reshape((-1, 28, 28, 1)).astype('float32')\n",
    "x_train = (x_train-127.5) / 127.5\n",
    "\n",
    "x_test = x_test_two.reshape((-1, 28, 28, 1)).astype('float32')\n",
    "x_test = (x_test_two-127.5) / 127.5\n",
    "x_train=x_train[:,:,:,]\n",
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Définition du générateur generator = tf.keras.Sequential()\n",
    "generator=tf.keras.Sequential()\n",
    "generator.add(tf.keras.layers.Dense(7*7*128, input_shape=(noise_dim,),use_bias=False,activation=\"tanh\"))\n",
    "\n",
    "generator.add(tf.keras.layers.BatchNormalization())\n",
    "generator.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "generator.add(tf.keras.layers.Reshape((7,7 ,128 )))\n",
    "\n",
    "\n",
    "generator.add(tf.keras.layers.Conv2DTranspose(64, kernel_size=(4,4), strides=(2,2), padding='same',use_bias=False))\n",
    "generator.add(tf.keras.layers.BatchNormalization())\n",
    "generator.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "\n",
    "\n",
    "generator.add(tf.keras.layers.Conv2DTranspose(32, kernel_size=(4,4), strides=(2,2), padding='same',use_bias=False))\n",
    "generator.add(tf.keras.layers.BatchNormalization())\n",
    "generator.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "\n",
    "generator.add(tf.keras.layers.Conv2DTranspose(1, kernel_size=(4,4), strides=(1,1), padding='same',use_bias=False,activation=\"tanh\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 6272)              627200    \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 6272)             25088     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_18 (LeakyReLU)  (None, 6272)              0         \n",
      "                                                                 \n",
      " reshape_6 (Reshape)         (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_12 (Conv2D  (None, 14, 14, 64)       131072    \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 14, 14, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_19 (LeakyReLU)  (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " conv2d_transpose_13 (Conv2D  (None, 28, 28, 32)       32768     \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 28, 28, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_20 (LeakyReLU)  (None, 28, 28, 32)        0         \n",
      "                                                                 \n",
      " conv2d_transpose_14 (Conv2D  (None, 28, 28, 1)        512       \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_21 (Bat  (None, 28, 28, 1)        4         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_21 (LeakyReLU)  (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 817,028\n",
      "Trainable params: 804,290\n",
      "Non-trainable params: 12,738\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Créer le discriminateur# Définition du modèle du discriminator\n",
    "discriminator = tf.keras.Sequential()\n",
    "\n",
    "\n",
    "discriminator.add(tf.keras.layers.Conv2D(32, (3, 3),strides=(2,2), padding='same', input_shape=(28, 28, 1)))\n",
    "discriminator.add(tf.keras.layers.BatchNormalization())\n",
    "discriminator.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "\n",
    "\n",
    "discriminator.add(tf.keras.layers.Conv2D(64, (3, 3),strides=(2,2), padding='same'))\n",
    "discriminator.add(tf.keras.layers.BatchNormalization())\n",
    "discriminator.add(tf.keras.layers.LeakyReLU(alpha=0.2))\n",
    "\n",
    "\n",
    "discriminator.add(tf.keras.layers.Flatten())\n",
    "discriminator.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 14, 14, 32)        320       \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 14, 14, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 14, 14, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 7, 7, 64)          18496     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 7, 7, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3136)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 3137      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,337\n",
      "Trainable params: 22,145\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "plot_model(discriminator)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compilations:\n",
    "Recompiler ne reset pas les poids, \n",
    "Cela permet d'actualiser les learning rates pour reprendre l'entrainement\n",
    "ou de changer la loss function\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonctions de perte utiles à la génération :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy=tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def discriminator_loss(real_output,fake_output):\n",
    "  d_loss_real = cross_entropy(tf.ones_like(real_output),fake_output)\n",
    "  d_loss_fake = cross_entropy(tf.zeros_like(real_output), fake_output)\n",
    "  d_loss=d_loss_fake+d_loss_real\n",
    "  return d_loss\n",
    "\n",
    "\n",
    "def generate_noise(batch_size, noise_dim):\n",
    "  return np.random.normal(0, 1, size=(batch_size, noise_dim))\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return tf.keras.losses.mean_squared_error(tf.ones_like(fake_output),fake_output)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sigma=1\n",
    "g_optimizer=tf.keras.optimizers.Adam(0.0001,(0.5,0,999))##8178 bons last\n",
    "d_optimizer=tf.keras.optimizers.Adam(0.0001,(0.5,0.999))## 2242"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from IPython import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "938"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUFFER_SIZE=60000\n",
    "batch_size=64\n",
    "train_dataset=tf.data.Dataset.from_tensor_slices(x_train)\n",
    "train_dataset=tf.data.Dataset.shuffle(self=train_dataset,buffer_size=BUFFER_SIZE)\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "len(train_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Hyperparametres\n",
    "\n",
    "num_generated_image=25\n",
    "noise_dim=100\n",
    "\n",
    "epochs=4\n",
    "\n",
    "num_discriminator_steps_per_epoch=3\n",
    "num_generator_steps_per_epoch=1\n",
    "\n",
    "input_shape=(28,28,1)\n",
    "seed=tf.random.normal([num_generated_image,noise_dim])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boucle d'entrainement, on effectue des batch à partir d'une fonction de génération de batchs définie précédemment ,à chaque itération on fait la fonction next qui prend un autre batch n'ayant pas été utilisé.\n",
    "Pour num_discriminator_steps_per_epoch on entraine le discriminateur avec des fausse images en réponse des 0 et des vrais images avec en réponses des 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = np.random.normal(0,1,[batch_size, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        gen_images=generator(noise,training=True)\n",
    "\n",
    "        real_output=discriminator(images,training=True)\n",
    "        fake_output=discriminator(gen_images,training=True)\n",
    "\n",
    "        g_loss=generator_loss(fake_output=fake_output)\n",
    "        d_loss=discriminator_loss(real_output,fake_output)\n",
    "\n",
    "        gradient_of_generator=gen_tape.gradient(g_loss,generator.trainable_variables)\n",
    "        gradient_of_dicriminator=disc_tape.gradient(d_loss,discriminator.trainable_variables)\n",
    "\n",
    "    g_optimizer.apply_gradients(zip(gradient_of_generator,generator.trainable_variables))\n",
    "    d_optimizer.apply_gradients(zip(gradient_of_dicriminator,discriminator.trainable_variables))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step_discriminator(images,noise):\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        \n",
    "        gen_images=generator(noise,training=True)\n",
    "\n",
    "        real_output=discriminator(images,training=True)\n",
    "        fake_output=discriminator(gen_images,training=True)\n",
    "\n",
    "        d_loss=discriminator_loss(real_output=real_output,fake_output=fake_output)\n",
    "        \n",
    "\n",
    "        gradient_of_discriminator=disc_tape.gradient(d_loss,discriminator.trainable_variables)\n",
    "\n",
    "    d_optimizer.apply_gradients(zip(gradient_of_discriminator,discriminator.trainable_variables))\n",
    "    noise = np.random.normal(0,sigma,[batch_size, noise_dim])\n",
    "    gen_images=generator(noise,training=True)\n",
    "        \n",
    "    real_output=discriminator(images,training=True)\n",
    "    fake_output=discriminator(gen_images,training=True)\n",
    "   \n",
    "    d_loss=discriminator_loss(real_output=real_output,fake_output=fake_output)\n",
    "    \n",
    "    return d_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step_generator(noise):\n",
    "    \n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        gen_images=generator(noise,training=True)\n",
    "\n",
    "        \n",
    "        fake_output=discriminator(gen_images,training=True)\n",
    "    \n",
    "        g_loss=generator_loss(fake_output=fake_output)\n",
    "        \n",
    "\n",
    "        gradient_of_generator=gen_tape.gradient(g_loss,generator.trainable_variables)\n",
    "\n",
    "    g_optimizer.apply_gradients(zip(gradient_of_generator,generator.trainable_variables))\n",
    "    noise = np.random.normal(0,sigma,[batch_size, noise_dim])\n",
    "    \n",
    "    gen_images=generator(noise,training=True)\n",
    "    fake_output=discriminator(gen_images,training=True)\n",
    "    g_loss=generator_loss(fake_output=fake_output)\n",
    "    \n",
    "   \n",
    "    return g_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model,epoch,test_input):\n",
    "    predictions=model(test_input,training=True)\n",
    "    fig=plt.figure(figsize=(4,4))\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4,4,i+1)\n",
    "        plt.imshow(predictions[i,:,:,0]*127.5+127.5,cmap='gray')\n",
    "        plt.axis('off')\n",
    "        \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time \n",
    "def train(dataset,epochs,num_discriminator_steps_per_epoch,num_generator_steps_per_epoch):\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        start=time.time()\n",
    "        \n",
    "        for image_batch in tqdm(dataset):\n",
    "            \n",
    "            for n in range(num_discriminator_steps_per_epoch):\n",
    "                noise = np.random.normal(0,sigma,[batch_size, noise_dim])\n",
    "                d_loss=train_step_discriminator(image_batch,noise)\n",
    "                print (\"Discriminator step:\",n+1)\n",
    "            \n",
    "            \n",
    "            for k in range(num_generator_steps_per_epoch):\n",
    "                noise = np.random.normal(0,sigma,[batch_size, noise_dim])\n",
    "                \n",
    "                print (\"Generator step:\",k+1)\n",
    "                g_loss=train_step_generator(noise)\n",
    "            \n",
    "            vis.line(\n",
    "                        X=torch.stack([Tensor(epochs)] * len(loss_legend), dim=1),\n",
    "                        Y=torch.stack((Tensor(d_losses), Tensor(g_losses)), dim=1),\n",
    "                        opts={\n",
    "                            'title': 'loss over time',\n",
    "                            'legend': loss_legend,\n",
    "                            'xlabel': 'epoch',\n",
    "                            'ylabel': 'loss',\n",
    "                            'width': 512,\n",
    "                            'height': 512\n",
    "                    },\n",
    "                        win=1)\n",
    "            vis.images(\n",
    "                        gen_images_seed,\n",
    "                        nrow=5, win=2,\n",
    "                        opts={\n",
    "                            'title': 'GAN output [Epoch {}]'.format(epoch),\n",
    "                            'width': 512,\n",
    "                            'height': 512,\n",
    "                        }\n",
    "                    )\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/938 [00:00<?, ?it/s]c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\backend.py:5676: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n",
      "  0%|          | 0/938 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\Utilisateur\\AppData\\Local\\Temp\\ipykernel_12892\\2419176986.py\", line 16, in train_step_discriminator  *\n        d_optimizer.apply_gradients(zip(gradient_of_discriminator,discriminator.trainable_variables))\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py\", line 1140, in apply_gradients  **\n        return super().apply_gradients(grads_and_vars, name=name)\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py\", line 634, in apply_gradients\n        iteration = self._internal_apply_gradients(grads_and_vars)\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py\", line 1166, in _internal_apply_gradients\n        return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py\", line 1216, in _distributed_apply_gradients_fn\n        distribution.extended.update(\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py\", line 1213, in apply_grad_to_update_var  **\n        return self._update_step(grad, var)\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py\", line 224, in _update_step\n        self.update_step(gradient, variable)\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\adam.py\", line 194, in update_step\n        m.assign_add((gradient - m) * (1 - self.beta_1))\n\n    TypeError: unsupported operand type(s) for -: 'int' and 'tuple'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12892\\3529439852.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_discriminator_steps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_generator_steps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12892\\470201620.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(dataset, epochs, num_discriminator_steps_per_epoch, num_generator_steps_per_epoch)\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_discriminator_steps_per_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m                 \u001b[0mnoise\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msigma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoise_dim\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m                 \u001b[0md_loss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_step_discriminator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnoise\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m                 \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"Discriminator step:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\UTILIS~1\\AppData\\Local\\Temp\\__autograph_generated_file3h9z2xm_.py\u001b[0m in \u001b[0;36mtf__train_step_discriminator\u001b[1;34m(images, noise)\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[0md_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiscriminator_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreal_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreal_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfake_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfake_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m                     \u001b[0mgradient_of_discriminator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdisc_tape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m                 \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_optimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradient_of_discriminator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m                 \u001b[0mnoise\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msigma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m                 \u001b[0mgen_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[1;34m(self, grads_and_vars, name, skip_gradients_aggregation, **kwargs)\u001b[0m\n\u001b[0;32m   1138\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mskip_gradients_aggregation\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mexperimental_aggregate_gradients\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m             \u001b[0mgrads_and_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maggregate_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1140\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply_weight_decay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[1;34m(self, grads_and_vars, name)\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_weight_decay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m         \u001b[0mgrads_and_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 634\u001b[1;33m         \u001b[0miteration\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_internal_apply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    635\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m         \u001b[1;31m# Apply variable constraints after applying gradients.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py\u001b[0m in \u001b[0;36m_internal_apply_gradients\u001b[1;34m(self, grads_and_vars)\u001b[0m\n\u001b[0;32m   1164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1165\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_internal_apply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1166\u001b[1;33m         return tf.__internal__.distribute.interim.maybe_merge_call(\n\u001b[0m\u001b[0;32m   1167\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_distributed_apply_gradients_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1168\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_distribution_strategy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py\u001b[0m in \u001b[0;36m_distributed_apply_gradients_fn\u001b[1;34m(self, distribution, grads_and_vars, **kwargs)\u001b[0m\n\u001b[0;32m   1214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m             distribution.extended.update(\n\u001b[0m\u001b[0;32m   1217\u001b[0m                 \u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapply_grad_to_update_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m             )\n",
      "\u001b[1;32mc:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py\u001b[0m in \u001b[0;36mapply_grad_to_update_var\u001b[1;34m(var, grad)\u001b[0m\n\u001b[0;32m   1211\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_step_xla\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_var_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1212\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1213\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py\u001b[0m in \u001b[0;36m_update_step\u001b[1;34m(self, gradient, variable)\u001b[0m\n\u001b[0;32m    222\u001b[0m                 \u001b[1;34m\"`tf.keras.optimizers.legacy.{self.__class__.__name__}.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m             )\n\u001b[1;32m--> 224\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcompute_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\adam.py\u001b[0m in \u001b[0;36mupdate_step\u001b[1;34m(self, gradient, variable)\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m             \u001b[1;31m# Dense gradients.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m             \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradient\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbeta_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m             \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbeta_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mamsgrad\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: in user code:\n\n    File \"C:\\Users\\Utilisateur\\AppData\\Local\\Temp\\ipykernel_12892\\2419176986.py\", line 16, in train_step_discriminator  *\n        d_optimizer.apply_gradients(zip(gradient_of_discriminator,discriminator.trainable_variables))\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py\", line 1140, in apply_gradients  **\n        return super().apply_gradients(grads_and_vars, name=name)\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py\", line 634, in apply_gradients\n        iteration = self._internal_apply_gradients(grads_and_vars)\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py\", line 1166, in _internal_apply_gradients\n        return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py\", line 1216, in _distributed_apply_gradients_fn\n        distribution.extended.update(\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py\", line 1213, in apply_grad_to_update_var  **\n        return self._update_step(grad, var)\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py\", line 224, in _update_step\n        self.update_step(gradient, variable)\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\adam.py\", line 194, in update_step\n        m.assign_add((gradient - m) * (1 - self.beta_1))\n\n    TypeError: unsupported operand type(s) for -: 'int' and 'tuple'\n"
     ]
    }
   ],
   "source": [
    "train(dataset=train_dataset,epochs=1,num_discriminator_steps_per_epoch=7,num_generator_steps_per_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(16,16))\n",
    "gen_test=generator(tf.random.normal([batch_size,noise_dim]))\n",
    "plt.imshow(gen_test[7],cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "image=generator.predict(seed)[0]\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(image, cmap='gray')\n",
    "\n",
    "# Afficher l'image de x_batch\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(x_train[0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "# Charger les données M\n",
    "# Obtenir les indices des images de 2 dans l'ensemble d'entraînement\n",
    "two_indices = np.where(y_test == 2)[0]\n",
    "\n",
    "# Sélectionner les images de 2 dans l'ensemble d'entraînement\n",
    "x_train_two = x_train[two_indices]\n",
    "\n",
    "y_train_two = y_train[two_indices]\n",
    "\n",
    "x_test_two = x_test[two_indices]\n",
    "\n",
    "y_test_two = y_test[two_indices]\n",
    "\n",
    "# Normaliser les données d'entraînement et de test\n",
    "x_train = x_train_two.astype('float32') / 255\n",
    "x_test = x_test_two.astype('float32') / 255\n",
    "\n",
    "# Redimensionner les données d'entraînement et de test en forme (batch_size, 28, 28, 1)\n",
    "x_train = x_train.reshape((-1, 28, 28, 1))\n",
    "x_test = x_test.reshape((-1, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/2 [==============>...............] - ETA: 11s - loss: 4.7464e-05WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 12s 294ms/step - loss: 4.7464e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25bbd2a6af0>"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise=np.random.normal(0,4,(batch_size,noise_dim))\n",
    "gan.fit(noise, real_labels, epochs=6, batch_size=batch_size,steps_per_epoch=2,validation_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 143ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "noise=np.random.normal(0,4,(batch_size,noise_dim))\n",
    "image=generator.predict(noise)[1]\n",
    "\n",
    "# Créer une figure\n",
    "plt.figure()\n",
    "\n",
    "# Afficher l'image\n",
    "plt.imshow(image, cmap='gray')\n",
    "\n",
    "# Afficher la figure\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 312ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(128, 56, 56, 1)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "num_epochs=40\n",
    "\n",
    "epochs=100\n",
    "batch_size=128\n",
    "num_discriminator_steps_per_epoch=6\n",
    "num_generator_steps_per_epoch=1\n",
    "noise_dim=100\n",
    "input_shape=(28,28,1)\n",
    "generateur.predict(noise).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/81\n",
      "3/3 [==============================] - 1s 42ms/step - loss: 15.4249\n",
      "Epoch 2/81\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 15.4249\n",
      "Epoch 3/81\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 15.4249\n",
      "Epoch 4/81\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 15.4249\n",
      "Epoch 5/81\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 15.4249\n",
      "Epoch 6/81\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 15.4249\n",
      "Epoch 7/81\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 15.4249\n",
      "Epoch 8/81\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 15.4249\n",
      "Epoch 9/81\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 15.4249\n",
      "Epoch 10/81\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 15.4249\n",
      "Epoch 11/81\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 15.4249\n",
      "Epoch 12/81\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 15.4249\n",
      "Epoch 13/81\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 15.4249"
     ]
    }
   ],
   "source": [
    "noise = np.random.normal(0,8, (batch_size, 100))\n",
    "\n",
    "gan.fit(noise,real_labels,epochs=81,validation_steps=1,steps_per_epoch=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 320ms/step\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'sequential_106/dropout_40/dropout/SelectV2' defined at (most recent call last):\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 390, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2914, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Utilisateur\\AppData\\Local\\Temp\\ipykernel_13812\\788602563.py\", line 24, in <module>\n      d_loss_fake = discriminator.train_on_batch(gen_images, fake_labels)\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 2478, in train_on_batch\n      logs = self.train_function(iterator)\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1023, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py\", line 413, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\layers\\regularization\\dropout.py\", line 120, in call\n      output = control_flow_util.smart_cond(\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\utils\\control_flow_util.py\", line 108, in smart_cond\n      return tf.__internal__.smart_cond.smart_cond(\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\layers\\regularization\\dropout.py\", line 116, in dropped_inputs\n      return self._random_generator.dropout(\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\backend.py\", line 2162, in dropout\n      return tf.nn.dropout(\nNode: 'sequential_106/dropout_40/dropout/SelectV2'\ncondition [128,7,7,32], then [128,14,14,32], and else [] must be broadcastable\n\t [[{{node sequential_106/dropout_40/dropout/SelectV2}}]] [Op:__inference_train_function_2618805]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13812\\788602563.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;31m# Entraîner le discriminateur sur le batch de données réelles et sur les images générées\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0md_loss_real\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreal_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0md_loss_fake\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfake_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;31m# Calculer la loss moyenne du discriminateur\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[0;32m   2476\u001b[0m             )\n\u001b[0;32m   2477\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2478\u001b[1;33m             \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2479\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2480\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential_106/dropout_40/dropout/SelectV2' defined at (most recent call last):\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 390, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2914, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Utilisateur\\AppData\\Local\\Temp\\ipykernel_13812\\788602563.py\", line 24, in <module>\n      d_loss_fake = discriminator.train_on_batch(gen_images, fake_labels)\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 2478, in train_on_batch\n      logs = self.train_function(iterator)\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1023, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py\", line 413, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\layers\\regularization\\dropout.py\", line 120, in call\n      output = control_flow_util.smart_cond(\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\utils\\control_flow_util.py\", line 108, in smart_cond\n      return tf.__internal__.smart_cond.smart_cond(\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\layers\\regularization\\dropout.py\", line 116, in dropped_inputs\n      return self._random_generator.dropout(\n    File \"c:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\keras\\backend.py\", line 2162, in dropout\n      return tf.nn.dropout(\nNode: 'sequential_106/dropout_40/dropout/SelectV2'\ncondition [128,7,7,32], then [128,14,14,32], and else [] must be broadcastable\n\t [[{{node sequential_106/dropout_40/dropout/SelectV2}}]] [Op:__inference_train_function_2618805]"
     ]
    }
   ],
   "source": [
    "generated_images=[]\n",
    "\n",
    "indices = np.random.randint(0, x_train.shape[0], size=batch_size)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  train_generator = generate_batch(x_train, batch_size)\n",
    "  # Entraîner le discriminateur\n",
    "  for _ in range(num_discriminator_steps_per_epoch):\n",
    "    # Sélectionner un batch de données réelles\n",
    "    \n",
    "    real_labels = np.ones((batch_size, 1))\n",
    "    fake_labels = np.zeros((batch_size, 1))\n",
    "\n",
    "    x_batch=next(train_generator)\n",
    "    \n",
    "    # Générer un bruit aléatoire\n",
    "    noise = np.random.normal(0,2,(batch_size, noise_dim))\n",
    "    \n",
    "    # Générer des images à partir du bruit\n",
    "    gen_images = generator.predict(noise)\n",
    "    generated_images.append(gen_images)\n",
    "    # Entraîner le discriminateur sur le batch de données réelles et sur les images générées\n",
    "    d_loss_real = discriminator.train_on_batch(x_batch, real_labels)\n",
    "    d_loss_fake = discriminator.train_on_batch(gen_images, fake_labels)\n",
    "    \n",
    "    # Calculer la loss moyenne du discriminateur\n",
    "    d_loss = 0.8 * np.add(d_loss_real, d_loss_fake)\n",
    "  \n",
    "  # Entraîner le générateur\n",
    "  for _ in range(num_generator_steps_per_epoch):\n",
    "    # Générer un bruit aléatoire\n",
    "    noise = np.random.normal(0,2,(batch_size, noise_dim))\n",
    "    \n",
    "    # Entraîner le générateur\n",
    "    g_loss = gan.train_on_batch(noise, real_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generated_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12812\\2417401207.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerated_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m   \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m   \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m   \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'off'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'generated_images' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for i, image in enumerate(generated_images):\n",
    "  plt.subplot(10, 10, i+1)\n",
    "  plt.imshow(image, cmap='gray')\n",
    "  plt.axis('off')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "66168a667a11ac16aca0d0d9742c8419f93457ff66115bf85239ea370d417636"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
